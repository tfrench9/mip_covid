Using TensorFlow backend.
Training data shape :  (2400, 224, 224) (2400,)
Testing data shape :  (600, 224, 224) (600,)
Total number of outputs :  3
Output classes :  [0. 1. 2.]

Colocations handled automatically by placer.
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 224, 224, 32)      832
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 32)      0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 112, 112, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 112, 112, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 112, 112, 64)      18496
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 112, 112, 64)      0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 56, 56, 64)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 56, 56, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 56, 128)       73856
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 56, 56, 128)       0
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 28, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 28, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 100352)            0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               12845184
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 128)               0
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 387
=================================================================
Total params: 12,938,755
Trainable params: 12,938,755
Non-trainable params: 0
_________________________________________________________________

Train on 2160 samples, validate on 240 samples
Epoch 1/20
2160/2160 [==============================] - 140s 65ms/step - loss: 2.1218 - accuracy: 0.3403 - val_loss: 1.1038 - val_accuracy: 0.3375
Epoch 2/20
2160/2160 [==============================] - 147s 68ms/step - loss: 1.0786 - accuracy: 0.4106 - val_loss: 1.1515 - val_accuracy: 0.3333
Epoch 3/20
2160/2160 [==============================] - 126s 58ms/step - loss: 1.0293 - accuracy: 0.4602 - val_loss: 1.0426 - val_accuracy: 0.4708
Epoch 4/20
2160/2160 [==============================] - 125s 58ms/step - loss: 0.9817 - accuracy: 0.5153 - val_loss: 0.8937 - val_accuracy: 0.5792
Epoch 5/20
2160/2160 [==============================] - 125s 58ms/step - loss: 0.8335 - accuracy: 0.6417 - val_loss: 0.8342 - val_accuracy: 0.6000
Epoch 6/20
2160/2160 [==============================] - 127s 59ms/step - loss: 0.8689 - accuracy: 0.5986 - val_loss: 0.8136 - val_accuracy: 0.6000
Epoch 7/20
2160/2160 [==============================] - 127s 59ms/step - loss: 0.6520 - accuracy: 0.7181 - val_loss: 0.8669 - val_accuracy: 0.6292
Epoch 8/20
2160/2160 [==============================] - 127s 59ms/step - loss: 0.4799 - accuracy: 0.8046 - val_loss: 0.8402 - val_accuracy: 0.6375
Epoch 9/20
2160/2160 [==============================] - 125s 58ms/step - loss: 0.3519 - accuracy: 0.8625 - val_loss: 0.8775 - val_accuracy: 0.6333
Epoch 10/20
2160/2160 [==============================] - 126s 58ms/step - loss: 0.2296 - accuracy: 0.9083 - val_loss: 1.3829 - val_accuracy: 0.6125
Epoch 11/20
2160/2160 [==============================] - 126s 58ms/step - loss: 0.1585 - accuracy: 0.9440 - val_loss: 1.1873 - val_accuracy: 0.6958
Epoch 12/20
2160/2160 [==============================] - 137s 64ms/step - loss: 0.1197 - accuracy: 0.9519 - val_loss: 1.1378 - val_accuracy: 0.6958
Epoch 13/20
2160/2160 [==============================] - 128s 59ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 1.0717 - val_accuracy: 0.7208
Epoch 14/20
2160/2160 [==============================] - 126s 58ms/step - loss: 0.0410 - accuracy: 0.9889 - val_loss: 1.5248 - val_accuracy: 0.6625
Epoch 15/20
2160/2160 [==============================] - 126s 58ms/step - loss: 0.0731 - accuracy: 0.9806 - val_loss: 2.0072 - val_accuracy: 0.5792
Epoch 16/20
2160/2160 [==============================] - 125s 58ms/step - loss: 0.0841 - accuracy: 0.9699 - val_loss: 1.4276 - val_accuracy: 0.6875
Epoch 17/20
2160/2160 [==============================] - 128s 59ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 1.1935 - val_accuracy: 0.6792
Epoch 18/20
2160/2160 [==============================] - 128s 59ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 1.4351 - val_accuracy: 0.6750
Epoch 19/20
2160/2160 [==============================] - 128s 59ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 1.3690 - val_accuracy: 0.7083
Epoch 20/20
2160/2160 [==============================] - 129s 60ms/step - loss: 0.0576 - accuracy: 0.9792 - val_loss: 1.2855 - val_accuracy: 0.7083
Test loss: 1.227621504465739
Test accuracy: 0.7333333492279053
